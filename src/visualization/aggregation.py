import os
import logging
import pandas as pd
import calendar
import json
import matplotlib.pyplot as plt
from matplotlib.offsetbox import AnchoredText

from argparse import ArgumentParser
from random import randint

from database.db_interface import MongoDBConnection
from config.config_parser import get_main_config_parser

parser = get_main_config_parser()
FIGSIZE = (14, 12)
PLOT_DIR = parser.get('visualization', 'plot_dir')
BBOX_TO_ANCHOR = (0.5, 0.05)
NCOL = 4
START_YR = parser.get('visualization', 'start_yr')
END_YR = parser.get('visualization', 'end_yr')
IMAGE_NAME = '{}/{}.png'.format(PLOT_DIR, '{}')
DPI = 300
COLORDICT_EXTENSIONS = {}
COLORDICT_YEARS = {}
COLORDICT_PLATFORMS = {}
COLORDICT_TYPES = {}

font = {
    'size': 17
}

plt.rc('font', **font)
plt.rcParams['axes.axisbelow'] = True


def format_file_name(name):
    """Replaces spaces, quotation marks, comma and hyphens in a name to a
    connectedly name to use as a filename.
    :param name (str): The name to convert.
    :return: The converted name as string.
    """
    return name.lower().replace(' ', '_').replace('"', '').replace(
        ',', '').replace('-', '_').replace('\n', '_')


def define_color_dict_for_file_extensions(df, create_map):
    """
    Defines a color mapping for file extensions. If create_map is true, it
    creates a new map; otherwise it reads an existing file.
    :param df (DataFrame): A DataFrame object.
    :param create_map (boolean): True to create a new map; False to read one.
    """
    global COLORDICT_EXTENSIONS
    path = parser.get('visualization', 'color_map_extensions')
    if create_map:
        all_extensions = \
            df['file'].str.split('.').str[1].unique().tolist()
        all_extensions.append('others')
        colors = []
        for i in range(len(all_extensions)):
            colors.append('#{:06X}'.format(randint(0, 0xFFFFFF)))
        for extension, color in zip(all_extensions, colors):
            COLORDICT_EXTENSIONS[extension] = color
        _write_color_map(COLORDICT_EXTENSIONS, path)
    else:
        COLORDICT_EXTENSIONS = _read_color_map(path)


def define_color_dict_for_years(df, create_map):
    """
    Defines a color mapping for years. If create_map is true, it
    creates a new map; otherwise it reads an existing file.
    :param df (DataFrame): A DataFrame object.
    :param create_map (boolean): True to create a new map; False to read one.
    """
    global COLORDICT_YEARS
    path = parser.get('visualization', 'color_map_years')
    if create_map:
        all_years = pd.to_datetime(df['date']).dt.year.unique().tolist()
        # in one plot all values are filled with 0, but for 1989 are no
        # exploits available. so we have to add it manually.
        all_years.append(1989)
        colors = [
            '#{:06x}'.format(randint(0, 0xFFFFFF))
            for _ in range(len(all_years))]
        for year, color in zip(all_years, colors):
            COLORDICT_YEARS[year] = color
            _write_color_map(COLORDICT_YEARS, path)
    else:
        def key_convert(dct):
            return {int(k): v for k, v in dct.iteritems()}
        COLORDICT_YEARS = _read_color_map(
            path, object_hook=lambda x: {int(k): v for k, v in x.iteritems()})


def define_color_dict_for_platforms(df, create_map):
    """
    Defines a color mapping for platforms. If create_map is true, it
    creates a new map; otherwise it reads an existing file.
    :param df (DataFrame): A DataFrame object.
    :param create_map (boolean): True to create a new map; False to read one.
    """
    global COLORDICT_PLATFORMS
    path = parser.get('visualization', 'color_map_platforms')
    if create_map:
        all_platforms = df['platform'].unique().tolist()
        all_platforms.append('others')
        colors = []
        for i in range(len(all_platforms)):
            colors.append('#{:06X}'.format(randint(0, 0xFFFFFF)))
        for platform, color in zip(all_platforms, colors):
            COLORDICT_PLATFORMS[platform] = color
            _write_color_map(COLORDICT_PLATFORMS, path)
    else:
        COLORDICT_PLATFORMS = _read_color_map(path)


def define_color_dict_for_types(df, create_map):
    """
    Defines a color mapping for types. If create_map is true, it
    creates a new map; otherwise it reads an existing file.
    :param df (DataFrame): A DataFrame object.
    :param create_map (boolean): True to create a new map; False to read one.
    """
    global COLORDICT_TYPES
    path = parser.get('visualization', 'color_map_types')
    if create_map:
        all_types = df['type'].unique().tolist()
        all_types.append('others')
        colors = []
        for i in range(len(all_types)):
            colors.append('#{:06X}'.format(randint(0, 0xFFFFFF)))
        for type_, color in zip(all_types, colors):
            COLORDICT_TYPES[type_] = color
            _write_color_map(COLORDICT_TYPES, path)
    else:
        COLORDICT_TYPES = _read_color_map(path)


def _write_color_map(color_map, path):
    """
    Write a color map to json file.
    :param color_map (dict): A dictionary of color mappping.
    :param path (str): The path to write the map to.
    """
    with open(path, 'w+') as f:
        json.dump(color_map, f)


def _read_color_map(path, object_hook=None):
    """
    Read a color map as json.
    :param path (str): The path to read the map from.
    :param object_hook (func): A Function to manipulate the json.
    :return: A dictionary of color map.
    """
    with open(path) as f:
        return json.load(f, object_hook=object_hook)


def get_simple_countings(df, start_yr=START_YR, end_yr=END_YR):
    """Generates simple counting statistics for the criterias ports, authors,
    platforms, file extensions and types of exploits. It determines the 10
    largest countings of each criteria.
    :param df (DataFrame): A DataFrame object.
    :param start_yr (str): The year when the counting should start; default
        is START_YR from config.
    :param end_yr (str): The year when the counting should end; default is
        END_YR from config.
    :return: A dictionary for the countings of ports, authors, platforms,
        file extensions and types as keys and a 3-tuple as values
        containing the DataFrame object, absolute size of exploit counting
        and the real occurrence in the 10 largest countings.
    """

    df.index = pd.to_datetime(df.date.values)
    df_year_range = df[start_yr:end_yr]

    ports = df_year_range['port']
    ports_size = ports.size - ports.isna().sum()
    ports_counts = ports.value_counts(dropna=True)
    nlargest_ports = ports_counts.nlargest(10)
    nlargest_ports.index = pd.Int64Index(nlargest_ports.index)
    nsmallest_ports_sum = ports_counts.nsmallest(ports_counts.size - 10).sum()
    nlargest_ports['others'] = nsmallest_ports_sum
    nlargest_ports = nlargest_ports.to_frame()
    nlargest_ports.rename(columns={'port': 'count'}, inplace=True)

    authors = df_year_range['author']
    authors_size = authors.size
    authors_counts = authors.value_counts(dropna=True)
    nlargest_authors = authors_counts.nlargest(10)
    nsmallest_authors_sum = authors_counts.nsmallest(
        authors_counts.size - 10).sum()
    nlargest_authors['others'] = nsmallest_authors_sum
    nlargest_authors = nlargest_authors.to_frame()
    nlargest_authors.rename(columns={'author': 'count'}, inplace=True)

    platforms = df_year_range['platform']
    platforms_size = platforms.size
    platforms_counts = platforms.value_counts(dropna=True)
    nlargest_platforms = platforms_counts.nlargest(10)
    nsmallest_platforms_sum = platforms_counts.nsmallest(
        platforms_counts.size - 10).sum()
    nlargest_platforms['others'] = nsmallest_platforms_sum
    nlargest_platforms = nlargest_platforms.to_frame()
    nlargest_platforms.rename(columns={'platform': 'count'}, inplace=True)

    files = df_year_range['file']
    files_size = files.size
    files_counts = files.str.split('.').str[1].value_counts()
    nlargest_files = files_counts.nlargest(10)
    nsmallest_files_sum = files_counts.nsmallest(files_counts.size - 10).sum()
    nlargest_files['others'] = nsmallest_files_sum
    nlargest_files = nlargest_files.to_frame()
    nlargest_files.rename(columns={'file': 'count'}, inplace=True)

    types = df_year_range['type']
    types_size = types.size
    types_counts = types.value_counts(dropna=True)
    nlargest_types = types_counts.nlargest(10)
    nsmallest_types_sum = types_counts.nsmallest(types_counts.size - 10).sum()
    nlargest_types['others'] = nsmallest_types_sum
    nlargest_types = nlargest_types.to_frame()
    nlargest_types.rename(columns={'type': 'count'}, inplace=True)

    return {
        'ports': (nlargest_ports, ports_size, ports_counts.size),
        'authors': (nlargest_authors, authors_size, authors_counts.size),
        'platforms': (nlargest_platforms, platforms_size,
                      platforms_counts.size),
        'file extensions': (nlargest_files, files_size, files_counts.size),
        'types': (nlargest_types, types_size, types_counts.size)
    }


def plot_simple_counting_statistics(df, size, title, critera, figsize,
                                    bbox_to_anchor, ncol):
    """Plots and saves five pie plots of simple countings by the criterias of
    ports, authors, platforms, file extensions and types.
    :param df (DataFrame): A DataFrame object.
    :param size (int): Size of the absolute counts of exploits by the specific
        criteria.
    :param title (str): Title of the plot.
    :param critera (str): The specific criteria title.
    :param figsize (tuple): The size of the plotted figure as a 2-tuple.
    :param bbox_to_anchor (tuple): Position of legend box as a 2-tuple.
    :param ncol (int): Number of columns in legend box.
    """
    # determine the right percentage quotations of each critera depending on
    # the 10 largest occurrences
    df_per_right = (df['count'] * 100) / size
    df_per_right.sort_values(ascending=False, inplace=True)
    # generate a list of labels for the legend of the plot
    labels = zip(df_per_right.values.round(2), df_per_right.index)
    if critera == 'platforms':
        colors = [
            COLORDICT_PLATFORMS[platform] for platform in df_per_right.index]
    elif critera == 'file extensions':
        colors = [COLORDICT_EXTENSIONS[ext] for ext in df_per_right.index]
    elif critera == 'types':
        colors = [COLORDICT_TYPES[type_] for type_ in df_per_right.index]
    else:
        colors = None
    pie_plot = df_per_right.plot.pie(title=title.title(),
                                     label='',
                                     labels=None,
                                     counterclock=False,
                                     figsize=figsize,
                                     startangle=90,
                                     colors=colors)
    pie_plot.legend(['{}% for "{}"'.format(per, index)
                     for per, index in labels], loc=9,
                    bbox_to_anchor=bbox_to_anchor, ncol=ncol,
                    title=critera.title())
    plt.savefig(IMAGE_NAME.format(format_file_name(title)), dpi=DPI)
    plt.close()


def plot_four_largest_years(df):
    """Plots and saves a bar plot of the four largest years.
    :param df (DataFrame): A DataFrame object.
    """
    # reindex
    df.index = pd.to_datetime(df.date.values)
    # resample by year and get four largest years
    df_year = df.resample('Y')
    years = df_year.count().nlargest(4, columns=['exploitdb_id']).index.year
    pv = pd.pivot_table(
        df, index=df.index.month,
        columns=df.index.year, values='exploitdb_id', aggfunc='count')
    # change number of month to month name
    pv.index = pv.index.map(lambda x: calendar.month_name[x])

    bar_plot = pv[years].plot.bar(
        title='4 Largest Years',
        figsize=(18, 16),
        color=[COLORDICT_YEARS[year] for year in years])
    bar_plot.set_xlabel('Month')
    bar_plot.set_ylabel('Counts')
    plt.grid()
    plt.savefig(IMAGE_NAME.format(format_file_name(bar_plot.get_title())),
                dpi=DPI)
    plt.close()


def plot_exploit_counts_in_date_range(df, start_yr=START_YR, end_yr=END_YR):
    """Plots and saves a bar plot of the sum of all exploits by year in a year
    range. It also plots and saves a bar plot with the sum of all exploits and
    vulnerabilities of the nvd by year in a year range.
    :param df (DataFrame): A DataFrame object.
    :param start_yr (str): The year when the bar should start; default is
        START_YR from config.
    :param end_yr (str): The year when the bar should end; default is END_YR
        from config.
    """
    df.index = pd.to_datetime(df.date.values)
    df_year_range = df[start_yr:end_yr].resample('Y')
    df_year_range_count = df_year_range['exploitdb_id'].count()
    df_year_range_count.index = df_year_range_count.index.year

    bar_plot = df_year_range_count.plot.bar(
        title='number of all exploits by year between {} and {}'.format(
            start_yr, end_yr).title(),
        figsize=FIGSIZE,
        color=[COLORDICT_YEARS[year] for year in df_year_range_count.index])

    for p in bar_plot.patches:
        bar_plot.annotate(int(p.get_height()),
                          (p.get_x() * 1.01, p.get_height() * 1.01))
    plt.ylim(top=20000)
    bar_plot.set_xlabel('Year')
    bar_plot.set_ylabel('Counts')
    plt.grid()
    plt.savefig(IMAGE_NAME.format(format_file_name(bar_plot.get_title())),
                dpi=DPI)
    plt.close()

    # plot exploit data together with nvd data
    # nvd data between 2009 and 2018:
    # https://nvd.nist.gov/vuln/search/statistics?form_type=Advanced&results_type=statistics&search_type=all&pub_start_date=01%2F01%2F2009&pub_end_date=12%2F31%2F2018
    df_nvd = pd.DataFrame(
        {
            'nvd': [
                5732, 4639, 4150, 5288, 5187, 7937, 6487, 6447, 14645, 16514
            ]
        })
    df_ex = df_year_range_count.to_frame().reset_index()
    df_conc = pd.concat([df_ex, df_nvd], axis=1)
    bar_line_plot = df_conc['exploitdb_id'].plot(
        kind='bar',
        color=[COLORDICT_YEARS[year] for year in df_conc['index']])

    text = '           ExDB | NVD\n'
    ex_nvd_list = [
            '{}:  {} | {}'.format(year, idx, val) for year, idx, val in zip(
                df_conc['index'], df_conc['exploitdb_id'], df_conc['nvd'])]
    text = '{}{}'.format(text, '\n'.join(ex_nvd_list))
    anchored_text = AnchoredText(text, loc=2)
    bar_line_plot = df_conc['nvd'].plot(
        title='number of all exploits and vulnerabilities by year between '
        '{} and {}'.format(start_yr, end_yr).title(),
        figsize=FIGSIZE,
        marker='o')

    bar_line_plot.set_xticklabels(df_conc['index'])
    bar_line_plot.add_artist(anchored_text)
    bar_line_plot.set_xlabel('Year')
    bar_line_plot.set_ylabel('Counts')
    plt.grid()
    plt.savefig(IMAGE_NAME.format(format_file_name(bar_line_plot.get_title())),
                dpi=DPI)
    plt.close()


def plot_most_exploit_types(df):
    """Plots and saves four bar plots in one plot of the most exploit types
    ordered by the day.
    :param df (DataFrame): A DataFrame object.
    """
    title = '10 days with most {} exploits'
    date_format = '%d %b %Y'
    fig, ax = plt.subplots(nrows=2, ncols=2, sharey=True, figsize=FIGSIZE)

    pivot_table = pd.pivot_table(
        df, index='date', columns='type', values='exploitdb_id',
        aggfunc='count')

    # generate new Series by pivot table and reindexing of each type
    webapps = pivot_table.dropna().nlargest(10, columns='webapps').sort_index()
    webapps.index = pd.to_datetime(webapps.index)
    dos = pivot_table.dropna().nlargest(10, columns='dos').sort_index()
    dos.index = pd.to_datetime(dos.index)
    local = pivot_table.dropna().nlargest(10, columns='local').sort_index()
    local.index = pd.to_datetime(local.index)
    remote = pivot_table.dropna().nlargest(10, columns='remote').sort_index()
    remote.index = pd.to_datetime(remote.index)

    webapps['webapps'].to_frame().plot.bar(
        ax=ax[0, 0],
        color=COLORDICT_TYPES['webapps'],
        title=title.format('webapps').title(),
        legend=None)
    dos['dos'].to_frame().plot.bar(
        ax=ax[0, 1],
        color=COLORDICT_TYPES['dos'],
        title=title.format('dos').title(),
        legend=None)
    local['local'].to_frame().plot.bar(
        ax=ax[1, 0],
        color=COLORDICT_TYPES['local'],
        title=title.format('local').title(),
        legend=None)
    remote['remote'].to_frame().plot.bar(
        ax=ax[1, 1],
        color=COLORDICT_TYPES['remote'],
        title=title.format('remote').title(),
        legend=None)

    # each type gets an own formatter for the date
    webapps_format = plt.FixedFormatter(
        webapps.index.to_series().dt.strftime(date_format))
    dos_format = plt.FixedFormatter(
        dos.index.to_series().dt.strftime(date_format))
    local_format = plt.FixedFormatter(
        local.index.to_series().dt.strftime(date_format))
    remote_format = plt.FixedFormatter(
        remote.index.to_series().dt.strftime(date_format))

    ax[0, 0].xaxis.set_major_formatter(webapps_format)
    ax[0, 1].xaxis.set_major_formatter(dos_format)
    ax[1, 0].xaxis.set_major_formatter(local_format)
    ax[1, 1].xaxis.set_major_formatter(remote_format)

    # set labels of each plot and set the absolute values to the top of each
    # bar
    for row in ax:
        for column in row:
            column.set_ylabel('Counts')
            column.set_xlabel('Date')
            for p in column.patches:
                column.annotate(int(p.get_height()),
                                (p.get_x() * 1.01, p.get_height() * 1.01))

    plt.tight_layout()
    plt.grid()
    plt.savefig(IMAGE_NAME.format(
        '10_days_with_most_exploited_types_by_date'), dpi=DPI)
    plt.close()


def plot_string_matchings_by_date_range(
        df, string_matches, start_yr=START_YR, end_yr=END_YR):
    """Plots and saves a pie plot of several strings which may contain in
    the description in a given date range.
    :param df (DataFrame): A DataFrame object.
    :param string_matches (list): A list of strings for matching.
    :param start_yr (str): The year when the pie plot should start; default is
        START_YR from config.
    :param end_yr (str): The year when the pie plot should end; default is
        END_YR from config.
    """
    df.index = pd.to_datetime(df['date'])
    str_counts = {}
    for string in string_matches:
        df_date_str = df[df['description'].str.lower().str.contains(string)]
        str_counts[string.split('|')[0].title()] = \
            df_date_str[start_yr:end_yr]['exploitdb_id'].count()
    total_exploits = df[start_yr:end_yr]['exploitdb_id'].count()
    str_counts['Others'] = total_exploits - sum(str_counts.values())
    se_counts = pd.DataFrame(str_counts, columns=['counts'],
                             index=str_counts.keys())
    se_counts['counts'] = pd.Series(str_counts)
    se_counts.sort_values(by=['counts'], ascending=False, inplace=True)
    pie_plot = se_counts.plot.pie(
        y='counts',
        title='matched vulnerabilities in exploit descriptions between {} and '
        '{}\n there are {} exploits in the given date range'
        '\nnot listed vulnerabilities are aggregated as others'.format(
            start_yr, end_yr, total_exploits).title(),
        figsize=FIGSIZE,
        label='',
        startangle=90,
        counterclock=False,
        labels=None)
    str_counts_sorted = sorted(
            str_counts.items(), key=lambda item: item[1], reverse=True)
    pie_plot.legend(['{} for "{}"'.format(val, crit)
                     for crit, val in str_counts_sorted], loc=9,
                    bbox_to_anchor=(0.5, 0.07), ncol=2,
                    title='Vulnerabilities')
    plt.savefig(IMAGE_NAME.format(format_file_name(pie_plot.get_title())),
                dpi=DPI)
    plt.close()


def plot_string_matchings_over_years(df, string_matches, start_yr=START_YR,
                                     end_yr=END_YR):
    """Plots and saves bar plots of several strings which may contain in
    the description summed by year.
    :param df (DataFrame): A DataFrame object.
    :param string_matches (list): A list of strings for matching.
    :param start_yr (str): The year when the barplot should start; default is
        START_YR from config.
    :param end_yr (str): The year when the barplot should end; default is
        END_YR from config.
    """
    df.index = pd.to_datetime(df['date'])
    for string in string_matches:
        df_date_str = df[df['description'].str.lower().str.contains(string)]
        df_date_str_re = df_date_str[start_yr:end_yr].resample('Y')
        df_date_counts = df_date_str_re['exploitdb_id'].value_counts().\
            to_frame()
        # remove multi index of dataframe
        df_date_reset = df_date_counts.unstack(level=1).xs(
            'exploitdb_id', axis=1, drop_level=True).reset_index()
        df_date_reset.index = df_date_reset['date'].dt.strftime('%Y')
        df_date_sum = df_date_reset.sum(axis=1)
        bar_plot = df_date_sum.plot.bar(
            title='matched "{}"-vulnerability in exploit description\nover '
            'the years between {} and {}'.format(
                string.split('|')[0], start_yr, end_yr).title(),
            figsize=FIGSIZE,
            color=[COLORDICT_YEARS[int(year)] for year in df_date_sum.index])

        for p in bar_plot.patches:
            bar_plot.annotate(int(p.get_height()),
                              (p.get_x() * 1.01, p.get_height() * 1.01))
        bar_plot.set_xlabel('Year')
        bar_plot.set_ylabel('Sum')
        plt.grid()
        plt.savefig(IMAGE_NAME.format(format_file_name(bar_plot.get_title())),
                    dpi=DPI)
        plt.close()


def plot_boxplot_by_type(df, start_yr=START_YR, end_yr=END_YR):
    """Plots and saves a boxplot by years of the specific exploit types.
    :param df (DataFrame): A DataFrame object.
    :param start_yr (str): The year when the boxplot should start; default is
        START_YR from config.
    :param end_yr (str): The year when the boxplot should end; default is
        END_YR from config.
    """
    # reindex
    df.index = pd.to_datetime(df['date'])
    # resample by month
    df_date_re = df[start_yr:end_yr].resample('M')
    df_date_counts = df_date_re.type.value_counts()
    # remove multi index of dataframe
    df_date_unstack = df_date_counts.to_frame().unstack(level=1)
    df_date_reset = df_date_unstack.xs(
        'type', axis=1, drop_level=True).reset_index()
    df_date_reset['date'] = df_date_reset['date'].dt.strftime('%Y')
    for item in ['dos', 'remote', 'local', 'webapps']:
        boxplot = df_date_reset[['date', item]].boxplot(
            by='date',
            figsize=FIGSIZE)
        boxplot.set_title('boxplot for type "{}" between year {} and '
                          '{}'.format(item, start_yr, end_yr).title())
        boxplot.set_xlabel('Year')
        boxplot.set_ylabel('Counts')
        plt.suptitle('')
        plt.savefig(IMAGE_NAME.format(format_file_name(boxplot.get_title())),
                    dpi=DPI)
        plt.close()


def plot_most_years_by_file_extension(df, extension, start_yr=START_YR,
                                      end_yr=END_YR):
    """Plots and saves a pie plot of the relation between exploit type and
    extension. Plots and saves a pie plot of the 10 largest exploit platforms
    by extension as well as a bar plot of most 10 years with number of exploits
    with extension.
    :param df (DataFrame): A DataFrame object.
    :param extension (str): The name of the extension.
    :param start_yr (str): The year when the pieplot should start; default is
        START_YR from config.
    :param end_yr (str): The year when the pieplot should end; default is
        END_YR from config.

    Returns:
        3-tuple.
            1. DatatimeIndexerResampler. DatatimeIndexerResampler object of all
            exploits filtered by the extension.
            2. DatatimeIndexerResampler. DatatimeIndexerResampler object of all
            exploits filtered by the extension and in the range of
            start_yr:end_yr.
            3. Series. Series object of filenames filtered by the extension.
    """

    files = df['file']
    ext_files = files[files.str.endswith('{}'.format(extension))]
    df_ext_files = df.loc[ext_files.index]
    # reindex
    df_ext_files.index = pd.to_datetime(df_ext_files['date'])
    # set range for reindexed data
    df_ext_files_date_by_range = df_ext_files[start_yr:end_yr]
    df_type_counts = df_ext_files_date_by_range['type'].value_counts()

    # first plot
    pie_plot = df_type_counts.plot.pie(
        autopct='%.2f%%',
        label='',
        title='relation between {} types and {} exploits with {}-extension '
        'between {} and {}'.format(
            df_type_counts.count(), len(df_ext_files_date_by_range),
            extension, start_yr, end_yr).title(),
        figsize=FIGSIZE,
        startangle=90,
        counterclock=False,
        colors=[COLORDICT_TYPES[type_] for type_ in df_type_counts.index])
    plt.savefig(IMAGE_NAME.format(format_file_name(pie_plot.get_title())),
                dpi=DPI)
    plt.close()

    # second plot
    df_ext_platforms_value_counts = \
        df_ext_files_date_by_range['platform'].value_counts()
    df_most_ext_platforms = df_ext_platforms_value_counts[:10]
    df_most_ext_platforms['others'] = \
        df_ext_platforms_value_counts[10:].sum()
    df_most_ext_platforms.sort_values(ascending=False, inplace=True)
    # generate a list of labels for the legend of the plot
    labels = zip(df_most_ext_platforms.values, df_most_ext_platforms.index)

    pie_plot = df_most_ext_platforms.plot.pie(
        title='10 most exploited platforms by {} {}-extension between {} and '
        '{}\nnot listed platforms are aggregated as others'.format(
            len(df_ext_files_date_by_range), extension, start_yr, end_yr
        ).title(),
        figsize=FIGSIZE,
        label='',
        labels=None,
        startangle=90,
        counterclock=False,
        colors=[
            COLORDICT_PLATFORMS[platform]
            for platform in df_most_ext_platforms.index])
    pie_plot.legend(['{} for "{}"'.format(val, index)
                     for val, index in labels], loc=9,
                    bbox_to_anchor=(0.5, 0.07), ncol=3,
                    title='Platforms')
    plt.savefig(IMAGE_NAME.format(format_file_name(pie_plot.get_title())),
                dpi=DPI)
    plt.close()

    # third plot
    # resample by year
    df_ext_files_re = df_ext_files_date_by_range.resample('Y')
    nlargest_ext = df_ext_files_re.count().nlargest(
        10, columns=['exploitdb_id'])['exploitdb_id'].sort_index()
    nlargest_ext.index = nlargest_ext.index.year

    bar_plot = nlargest_ext.plot.bar(
        figsize=FIGSIZE,
        title='most 10 years between {} and {} with number of exploits with '
        '{}-extension'.format(start_yr, end_yr, extension).title(),
        color=[COLORDICT_YEARS[year] for year in nlargest_ext.index])

    # set labels of each plot and set the absolute values to the top of each
    # bar
    for p in bar_plot.patches:
        bar_plot.annotate(int(p.get_height()),
                          (p.get_x() * 1.01, p.get_height() * 1.01))
    bar_plot.set_xlabel('Year')
    bar_plot.set_ylabel('Counts')
    plt.grid()
    plt.savefig(IMAGE_NAME.format(format_file_name(bar_plot.get_title())),
                dpi=DPI)
    plt.close()

    # fourth plot
    # resample range data by year
    df_ext_files_re_by_range = df_ext_files_date_by_range.resample('Y')

    ext_count = df_ext_files_re_by_range.count()['exploitdb_id']
    ext_count.index = ext_count.index.year

    bar_plot = ext_count.plot.bar(
        figsize=FIGSIZE,
        title='number of exploits between {} and {} with {}-extension'.format(
            start_yr, end_yr, extension).title(),
        color=[COLORDICT_YEARS[year] for year in ext_count.index])

    # set labels of each plot and set the absolute values to the top of each
    # bar
    for p in bar_plot.patches:
        bar_plot.annotate(int(p.get_height()),
                          (p.get_x() * 1.01, p.get_height() * 1.01))
    bar_plot.set_xlabel('Year')
    bar_plot.set_ylabel('Counts')
    plt.grid()
    plt.savefig(IMAGE_NAME.format(format_file_name(bar_plot.get_title())),
                dpi=DPI)
    plt.close()

    return df_ext_files.resample('Y'), df_ext_files_re_by_range, ext_files


def plot_file_extension_by_years_together(df, ext_df, start_yr=START_YR,
                                          end_yr=END_YR):
    """Plots exploits by file extensions together in one bar plot. It is
    represented in relative as well as absolute numbers in a year range and
    without.
    :param df (DataFrame): A DataFrame object.
    :param ext_df (dict): Dictionary which contains the extension as key
        and a 3-tuple defined as followed:
            1. DatatimeIndexerResampler. DatatimeIndexerResampler object
            of all exploits filtered by the extension.
            2. DatatimeIndexerResampler. DatatimeIndexerResampler object
            of all exploits filtered by the extension and in the range of
            start_yr:end_yr.
            3. Series. Series object of filenames filtered by the
            extension.
    :param start_yr (str): The year when the barplot should start; default is
        START_YR from config.
    :param end_yr (str): The year when the barplot should end; default is
        END_YR from config.
    """
    files = df['file']
    diff_idx = pd.Int64Index([])
    ext_files_count_list = []
    ext_files_count_by_range_list = []

    for df_ext_files_re, df_ext_files_re_by_range, ext_files \
            in ext_df.values():
        diff_idx = diff_idx.append(ext_files.index)

        ext_files_count = df_ext_files_re.count()['exploitdb_id'].sort_index()
        ext_files_count.index = ext_files_count.index.year
        ext_files_count_list.append(ext_files_count)

        ext_files_count_by_range = df_ext_files_re_by_range.count()[
            'exploitdb_id'].sort_index()
        ext_files_count_by_range.index = ext_files_count_by_range.index.year
        ext_files_count_by_range_list.append(ext_files_count_by_range)

    # subtract all defined extensions from all other extensions to build a
    # disjunct set
    files_diff = files[files.index.difference(diff_idx)]
    other_ext_files = df.loc[files_diff.index]

    other_ext_files_date = other_ext_files.copy()
    other_ext_files_date.index = pd.to_datetime(other_ext_files_date['date'])

    ext_df_keys = ext_df.keys()
    ext_df_keys.append('others')

    _plot_file_extension_by_years_together_helper(
        other_ext_files_date, ext_files_count_list, ext_df_keys,
        'all years with absolute number of exploits with {} extensions'
        '\nnot listed extensions are aggregated as others'.format(
            ', '.join(ext_df.keys())).title(),
        'all years with relative number of exploits with {} extensions'
        '\nnot listed extensions are aggregated as others'.format(
            ', '.join(ext_df.keys())).title())

    other_ext_files_date_by_range = other_ext_files_date.loc[start_yr:end_yr]
    title_abs = 'absolute number of exploits between {} and ' \
        '{} with {} extensions\nnot listed extensions are aggregated as ' \
        'others'.format(start_yr, end_yr, ', '.join(ext_df.keys())).title()
    title_rel = 'relative number of exploits between {} and ' \
        '{} with {} extensions\nnot listed extensions are aggregated as ' \
        'others'.format(start_yr, end_yr,  ', '.join(ext_df.keys())).title()
    _plot_file_extension_by_years_together_helper(
        other_ext_files_date_by_range, ext_files_count_by_range_list,
        ext_df_keys, title_abs, title_rel)


def _plot_file_extension_by_years_together_helper(
        other_ext_files_date, ext_files_count_list, ext_df_keys, title_abs,
        title_rel):
    """Helper function to plot exploits by file extensions together in one bar
    plot. It calculates the plot in absolute and relative numbers.
    :param other_ext_files_date (DataFrame): A DataFram object with all exploit
        information with date as index.
    :param ext_files_count_list (list): A list with all Series objects of all
        extensions.
    :param ext_df_keys (list): All extensions as a list.
    :param title_abs (str): A title for the absolute plot bar.
    :param title_rel (str): A title for the relative plot bar.
    """
    other_ext_files_re = other_ext_files_date.resample('Y')
    other_ext_files_count = other_ext_files_re.count()[
        'exploitdb_id'].sort_index()
    other_ext_files_count.index = other_ext_files_count.index.year

    ext_files_count_list.append(other_ext_files_count)

    df_conc = pd.concat(
        ext_files_count_list, keys=ext_df_keys, axis=1).fillna(0)

    bar_plot = df_conc.plot.bar(
        figsize=FIGSIZE,
        title=title_abs,
        color=[COLORDICT_EXTENSIONS[ext] for ext in df_conc.columns])
    bar_plot.set_xlabel('Year')
    bar_plot.set_ylabel('Counts')
    plt.grid()
    plt.savefig(IMAGE_NAME.format(
        format_file_name(bar_plot.get_title()), dpi=DPI))
    plt.close()

    df_conc_perc = 100 * df_conc.apply(lambda x: x / x.sum(), axis=1)
    bar_plot = df_conc_perc.plot.bar(
        figsize=FIGSIZE,
        title=title_rel,
        color=[COLORDICT_EXTENSIONS[ext] for ext in df_conc_perc.columns])

    # set y-axis to a uniform maximum
    plt.ylim(top=102.0)
    bar_plot.set_xlabel('Year')
    bar_plot.set_ylabel('Percentage')
    bar_plot.set_yticklabels(
        ['{}%'.format(int(x)) for x in bar_plot.get_yticks()])

    plt.grid()
    plt.savefig(IMAGE_NAME.format(
        format_file_name(bar_plot.get_title()), dpi=DPI))
    plt.close()


def plot_most_years_by_file_extension_together(df, ext_df, start_yr=START_YR,
                                               end_yr=END_YR):
    """Plots the most years of exploits by file extensions together in one
    bar plot. It is represented in relative as well as absolute numbers in a
    year range and without.
    :param df (DataFrame): A DataFrame object.
    :param ext_df (dict): Dictionary which contains the extension as key
        and a 3-tuple defined as followed:
            1. DatatimeIndexerResampler. DatatimeIndexerResampler object
            of all exploits filtered by the extension.
            2. DatatimeIndexerResampler. DatatimeIndexerResampler object
            of all exploits filtered by the extension and in the range of
            start_yr:end_yr.
            3. Series. Series object of filenames filtered by the
            extension.
    :param start_yr (str): The year when the barplot should start; default is
        START_YR from config.
    :param end_yr (str): The year when the barplot should end; default is
        END_YR from config.
    """
    files = df['file']
    diff_idx = pd.Int64Index([])
    nlargest_ext_list = []
    nlargest_ext_by_range_list = []

    for df_ext_files_re, df_ext_files_re_by_range, ext_files \
            in ext_df.values():
        diff_idx = diff_idx.append(ext_files.index)

        nlargest_ext = df_ext_files_re.count().nlargest(
            10, columns=['exploitdb_id'])['exploitdb_id'].sort_index()
        nlargest_ext.index = nlargest_ext.index.year
        nlargest_ext_list.append(nlargest_ext)

        nlargest_ext_by_range = df_ext_files_re_by_range.count().nlargest(
            10, columns=['exploitdb_id'])['exploitdb_id'].sort_index()
        nlargest_ext_by_range.index = nlargest_ext_by_range.index.year
        nlargest_ext_by_range_list.append(nlargest_ext_by_range)

    # subtract all defined extensions from all other extensions to build a
    # disjunct set
    files_diff = files[files.index.difference(diff_idx)]
    other_ext_files = df.loc[files_diff.index]

    other_ext_files_date = other_ext_files.copy()
    other_ext_files_date.index = pd.to_datetime(other_ext_files_date['date'])

    ext_df_keys = ext_df.keys()
    ext_df_keys.append('others')

    # build up nlargest others
    _plot_most_years_by_file_extension_together_helper(
        other_ext_files_date, nlargest_ext_list, ext_df_keys,
        'most years with absolute number of exploits with {} extensions'
        '\nnot listed extensions are aggregated as others'.format(
            ', '.join(ext_df.keys())).title(),
        'most years with relative number of exploits with {} extensions'
        '\nnot listed extensions are aggregated as others'.format(
            ', '.join(ext_df.keys())).title())

    # build up nlargest others by range
    other_ext_files_date_by_range = other_ext_files_date.loc[start_yr:end_yr]
    title_abs = 'most years with absolute number of exploits between {} and ' \
        '{} with {} extensions\nnot listed extensions are aggregated as ' \
        'others'.format(start_yr, end_yr, ', '.join(ext_df.keys())).title()
    title_rel = 'most years with relative number of exploits between {} and ' \
        '{} with {} extensions\not listed extensions are aggregated as ' \
        'others'.format(start_yr, end_yr,  ', '.join(ext_df.keys())).title()
    _plot_most_years_by_file_extension_together_helper(
        other_ext_files_date_by_range, nlargest_ext_by_range_list, ext_df_keys,
        title_abs, title_rel)


def _plot_most_years_by_file_extension_together_helper(
        other_ext_files_date, nlargest_ext_list, ext_df_keys, title_abs,
        title_rel):
    """Helper function to plot the most years of exploits by file extensions
    together in one bar plot. It calculates the plot in absolute and relative
    numbers.
    :param other_ext_files_date (DataFrame): A DataFram object with all exploit
        information with date as index.
    :param nlargest_ext_list (list): A list with all nlargest Series objects of
        all extensions.
    :param ext_df_keys (list): All extensions as a list.
    :param title_abs (str): A title for the absolute plot bar.
    :param title_rel (str): A title for the relative plot bar.
    """
    other_ext_files_re = other_ext_files_date.resample('Y')
    nlargest_other_ext = other_ext_files_re.count().nlargest(
        10, columns=['exploitdb_id'])['exploitdb_id'].sort_index()
    nlargest_other_ext.index = nlargest_other_ext.index.year

    nlargest_ext_list.append(nlargest_other_ext)

    df_conc = pd.concat(nlargest_ext_list, keys=ext_df_keys, axis=1).fillna(0)
    bar_plot = df_conc.plot.bar(
        figsize=FIGSIZE,
        title=title_abs,
        color=[COLORDICT_EXTENSIONS[ext] for ext in df_conc.columns])
    bar_plot.set_xlabel('Year')
    bar_plot.set_ylabel('Counts')
    plt.grid()
    plt.savefig(IMAGE_NAME.format(
        format_file_name(bar_plot.get_title()), dpi=DPI))
    plt.close()

    df_conc_perc = 100 * df_conc.apply(lambda x: x / x.sum(), axis=1)
    bar_plot = df_conc_perc.plot.bar(
        figsize=FIGSIZE,
        title=title_rel,
        color=[COLORDICT_EXTENSIONS[ext] for ext in df_conc_perc.columns])

    # set y-axis to a uniform maximum
    plt.ylim(top=102.0)
    bar_plot.set_xlabel('Year')
    bar_plot.set_ylabel('Percentage')
    bar_plot.set_yticklabels(
        ['{}%'.format(int(x)) for x in bar_plot.get_yticks()])

    plt.grid()
    plt.savefig(IMAGE_NAME.format(
        format_file_name(bar_plot.get_title()), dpi=DPI))
    plt.close()


def plot_most_platforms_by_extensions(df, common_platforms, start_yr=START_YR,
                                      end_yr=END_YR):
    """
    Plot most platforms correlated with file extensions in a year range.
    :param df (DataFrame): A DataFrame object.
    :param common_platforms (list): A list of common platforms to filter by.
    :param start_yr (str): The year when the pie plot should start; default is
        START_YR from config.
    :param end_yr (str): The year when the pie plot should end; default is
        END_YR from config.
    """

    df.index = pd.to_datetime(df.date.values)
    df_year_range = df[start_yr:end_yr]
    for platform in common_platforms:
        # match with given platform
        df_platform = df_year_range.loc[df_year_range['platform'] == platform]
        # expand split filename and save extension data
        df_file_ext = df_platform['file'].str.split('.').str[1]
        df_counts = df_file_ext.value_counts()[:10]
        df_counts['others'] = df_file_ext.value_counts()[10:].sum()

        df_counts = df_counts.to_frame()
        df_counts_per = (df_counts['file'] * 100) / df_file_ext.size
        df_counts_per.sort_values(ascending=False, inplace=True)

        title = 'most 10 used file extensions by platform {} between {} and '\
            '{} for {} exploits\n' \
            'not listed extensions are aggregated as others'.format(
                platform, start_yr, end_yr, df_file_ext.count()).title()
        labels = zip(df_counts_per.values.round(2), df_counts_per.index)

        pie_plot = df_counts_per.plot.pie(
            title=title,
            figsize=FIGSIZE,
            label='',
            labels=None,
            startangle=90,
            counterclock=False,
            colors=[COLORDICT_EXTENSIONS[ext] for ext in df_counts_per.index])
        pie_plot.legend(['{}% for "{}"'.format(per, index)
                         for per, index in labels], loc=9,
                        bbox_to_anchor=BBOX_TO_ANCHOR, ncol=NCOL,
                        title='File Extensions')
        plt.savefig(IMAGE_NAME.format(format_file_name(pie_plot.get_title())),
                    dpi=DPI)
        plt.close()


def main(args):
    """
    Main routine to plot statistics.
    :param args (argsparse.Namespace): Parsed argumnets object.
    """
    database_logger = logging.getLogger(parser.get('logging', 'database'))
    db = MongoDBConnection(database_logger)

    # delete all files containing in asset dir. this is needed in case of new
    # exploits in database because in some filenames the counting of exploits
    # is represented
    map(
        os.unlink,
        (os.path.join(PLOT_DIR, f) for f in os.listdir(PLOT_DIR)))

    simple_counting_items = [
        ('ports', 'most used ports out of {} available ports between {} and {}'
         '\nthere are {} exploits which have a port entry\n'
         'not listed ports are aggregated as others', FIGSIZE, BBOX_TO_ANCHOR,
         NCOL, START_YR, END_YR),
        ('authors', 'most authors out of {} available authors between {} '
         'and {}\n'
         'there are {} exploits which have an author entry\n'
         'not listed authors are aggregated as others', (16, 14), (0.5, 0.07),
         3, START_YR, END_YR),
        ('platforms', 'most exploited platforms out of {} available platforms '
         'between {} and {}\n'
         'there are {} exploits which have a platform entry\n'
         'not listed platforms are aggregated as others', (16, 14),
         (0.5, 0.07), 3, START_YR, END_YR),
        ('file extensions', 'most used file extensions out of {} found '
         'file extensions between {} and {}\n'
         'there are {} exploits which have a file extension\n'
         'not listed files extensions are aggregated as others', FIGSIZE,
         BBOX_TO_ANCHOR, NCOL, START_YR, END_YR),
        ('types', 'most used types out of {} available types between {} and {}'
         '\nthere are {} exploits which have a type entry\n'
         'not listed types are aggregated as others', FIGSIZE, BBOX_TO_ANCHOR,
         2, START_YR, END_YR)
    ]
    vul_types = [
        'sql injection|sqli', 'denial of service|dos',
        'remote code execution|remote code',
        'cross-site scripting|cross site scripting|xss',
        'cross-site request forgery|csrf', 'buffer overflow',
        'authentication bypass']

    ####
    # get and prepare exploit data
    ####
    df = pd.DataFrame(db.get_all_exploits())

    df.columns.name = 'exploits'
    df.rename(columns={'id': 'exploitdb_id'}, inplace=True)

    define_color_dict_for_file_extensions(df, args.e)
    define_color_dict_for_years(df, args.y)
    define_color_dict_for_platforms(df, args.p)
    define_color_dict_for_types(df, args.t)
    ####
    # start plotting statistics
    ####
    simple_counts = get_simple_countings(df.copy())
    for item, comment, figsize, bbox_to_anchor, ncol, start_yr, end_yr in\
            simple_counting_items:
        plot_simple_counting_statistics(
            simple_counts[item][0],
            simple_counts[item][1],
            comment.format(
                simple_counts[item][2],
                start_yr,
                end_yr,
                simple_counts[item][1]),
            item, figsize, bbox_to_anchor, ncol)

    plot_four_largest_years(df.copy())

    plot_exploit_counts_in_date_range(df.copy())

    plot_most_exploit_types(df.copy())

    plot_string_matchings_by_date_range(df.copy(), vul_types)

    plot_string_matchings_over_years(df.copy(), vul_types)

    plot_boxplot_by_type(df.copy())

    ext_df = {}
    # most 5 used file extensions
    most_common_extensions = \
        simple_counts['file extensions'][0].iloc[0:6].index
    for ext in most_common_extensions:
        df_ext = plot_most_years_by_file_extension(df.copy(), ext)
        ext_df[ext] = df_ext
    # for a cleaner bar plot remove txt exploits
    # ext_df.pop('txt')
    # does not make sense at the moment to plot this kind of charts
    plot_most_years_by_file_extension_together(df.copy(), ext_df)

    plot_file_extension_by_years_together(df.copy(), ext_df)

    most_common_platforms = simple_counts['platforms'][0].iloc[0:4].index
    plot_most_platforms_by_extensions(df.copy(), most_common_platforms)

    db.close()


if __name__ == "__main__":
    arg_pars = ArgumentParser(
        description='Create new or read existing color maps.')
    arg_pars.add_argument(
        '-e',
        action='store_true',
        default=False,
        help='Creates a new color map for file extensions; default is False '
        'and it reads the existing color map.')
    arg_pars.add_argument(
        '-y',
        action='store_true',
        default=False,
        help='Creates a new color map for years; default is False and it '
        'reads the existing color map.')
    arg_pars.add_argument(
        '-p',
        action='store_true',
        default=False,
        help='Creates a new color map for platforms; default is False and it '
        'reads the existing color map.')
    arg_pars.add_argument(
        '-t',
        action='store_true',
        default=False,
        help='Creates a new color map for types; default is False and it '
        'reads the existing color map.')
    args = arg_pars.parse_args()
    main(args)
